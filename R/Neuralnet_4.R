#this code written for self educational purposes may not work on you due to missing packages/input files

#replacing missing values of each column with aritmetic averages that belongs the same column

train_iris$x001[is.na(train_iris$x001)] <- round(mean(train_iris$x001, na.rm = TRUE))
train_iris$x002[is.na(train_iris$x002)] <- round(mean(train_iris$x002, na.rm = TRUE))
train_iris$x003[is.na(train_iris$x003)] <- round(mean(train_iris$x003, na.rm = TRUE))
train_iris$x004[is.na(train_iris$x004)] <- round(mean(train_iris$x004, na.rm = TRUE))
train_iris$x005[is.na(train_iris$x005)] <- round(mean(train_iris$x005, na.rm = TRUE))
train_iris$x006[is.na(train_iris$x006)] <- round(mean(train_iris$x006, na.rm = TRUE))
train_iris$x007[is.na(train_iris$x007)] <- round(mean(train_iris$x007, na.rm = TRUE)) 
train_iris$x008[is.na(train_iris$x008)] <- round(mean(train_iris$x008, na.rm = TRUE))
train_iris$x009[is.na(train_iris$x009)] <- round(mean(train_iris$x009, na.rm = TRUE))
train_iris$x010[is.na(train_iris$x010)] <- round(mean(train_iris$x010, na.rm = TRUE))
train_iris$x011[is.na(train_iris$x011)] <- round(mean(train_iris$x011, na.rm = TRUE))
train_iris$x012[is.na(train_iris$x012)] <- round(mean(train_iris$x012, na.rm = TRUE))
train_iris$x013[is.na(train_iris$x013)] <- round(mean(train_iris$x013, na.rm = TRUE))
train_iris$x014[is.na(train_iris$x014)] <- round(mean(train_iris$x014, na.rm = TRUE))
train_iris$x015[is.na(train_iris$x015)] <- round(mean(train_iris$x015, na.rm = TRUE))
train_iris$x016[is.na(train_iris$x016)] <- round(mean(train_iris$x016, na.rm = TRUE))
train_iris$x017[is.na(train_iris$x017)] <- round(mean(train_iris$x017, na.rm = TRUE))
train_iris$x018[is.na(train_iris$x018)] <- round(mean(train_iris$x018, na.rm = TRUE))
train_iris$x019[is.na(train_iris$x019)] <- round(mean(train_iris$x019, na.rm = TRUE))
train_iris$x020[is.na(train_iris$x020)] <- round(mean(train_iris$x020, na.rm = TRUE))
train_iris$x021[is.na(train_iris$x021)] <- round(mean(train_iris$x021, na.rm = TRUE))
train_iris$x022[is.na(train_iris$x022)] <- round(mean(train_iris$x022, na.rm = TRUE))
train_iris$x023[is.na(train_iris$x023)] <- round(mean(train_iris$x023, na.rm = TRUE))
train_iris$x024[is.na(train_iris$x024)] <- round(mean(train_iris$x024, na.rm = TRUE))
train_iris$x025[is.na(train_iris$x025)] <- round(mean(train_iris$x025, na.rm = TRUE))
train_iris$x026[is.na(train_iris$x026)] <- round(mean(train_iris$x026, na.rm = TRUE))
train_iris$x027[is.na(train_iris$x027)] <- round(mean(train_iris$x027, na.rm = TRUE))
train_iris$x028[is.na(train_iris$x028)] <- round(mean(train_iris$x028, na.rm = TRUE))
train_iris$x029[is.na(train_iris$x029)] <- round(mean(train_iris$x029, na.rm = TRUE))
train_iris$x030[is.na(train_iris$x030)] <- round(mean(train_iris$x030, na.rm = TRUE))
train_iris$x031[is.na(train_iris$x031)] <- round(mean(train_iris$x031, na.rm = TRUE))
train_iris$x032[is.na(train_iris$x032)] <- round(mean(train_iris$x032, na.rm = TRUE))
train_iris$x033[is.na(train_iris$x033)] <- round(mean(train_iris$x033, na.rm = TRUE))
train_iris$x034[is.na(train_iris$x034)] <- round(mean(train_iris$x034, na.rm = TRUE))
train_iris$x035[is.na(train_iris$x035)] <- round(mean(train_iris$x035, na.rm = TRUE))
train_iris$x036[is.na(train_iris$x036)] <- round(mean(train_iris$x036, na.rm = TRUE))
train_iris$x037[is.na(train_iris$x037)] <- round(mean(train_iris$x037, na.rm = TRUE))
train_iris$x038[is.na(train_iris$x038)] <- round(mean(train_iris$x038, na.rm = TRUE))
train_iris$x039[is.na(train_iris$x039)] <- round(mean(train_iris$x039, na.rm = TRUE))
train_iris$x040[is.na(train_iris$x040)] <- round(mean(train_iris$x040, na.rm = TRUE))
train_iris$x041[is.na(train_iris$x041)] <- round(mean(train_iris$x041, na.rm = TRUE))
train_iris$x042[is.na(train_iris$x042)] <- round(mean(train_iris$x042, na.rm = TRUE))
train_iris$x043[is.na(train_iris$x043)] <- round(mean(train_iris$x043, na.rm = TRUE))
train_iris$x044[is.na(train_iris$x044)] <- round(mean(train_iris$x044, na.rm = TRUE))
train_iris$x045[is.na(train_iris$x045)] <- round(mean(train_iris$x045, na.rm = TRUE))
train_iris$x046[is.na(train_iris$x046)] <- round(mean(train_iris$x046, na.rm = TRUE))
train_iris$x047[is.na(train_iris$x047)] <- round(mean(train_iris$x047, na.rm = TRUE))
train_iris$x048[is.na(train_iris$x048)] <- round(mean(train_iris$x048, na.rm = TRUE))
train_iris$x049[is.na(train_iris$x049)] <- round(mean(train_iris$x049, na.rm = TRUE))
train_iris$x050[is.na(train_iris$x050)] <- round(mean(train_iris$x050, na.rm = TRUE))
train_iris$x051[is.na(train_iris$x051)] <- round(mean(train_iris$x051, na.rm = TRUE))
train_iris$x052[is.na(train_iris$x052)] <- round(mean(train_iris$x052, na.rm = TRUE))
train_iris$x053[is.na(train_iris$x053)] <- round(mean(train_iris$x053, na.rm = TRUE))
train_iris$x054[is.na(train_iris$x054)] <- round(mean(train_iris$x054, na.rm = TRUE))
train_iris$x055[is.na(train_iris$x055)] <- round(mean(train_iris$x055, na.rm = TRUE))
train_iris$x056[is.na(train_iris$x056)] <- round(mean(train_iris$x056, na.rm = TRUE))
train_iris$x057[is.na(train_iris$x057)] <- round(mean(train_iris$x057, na.rm = TRUE))





install.packages("neuralnet")

library(neuralnet)
y <- bigdf$x001
x2 <- bigdf$x002
x3 <- bigdf$x003
x4 <- bigdf$x004
x5 <- bigdf$x005
x6 <- bigdf$x006
x7 <- bigdf$x007

nn = neuralnet(y~x2+x3+x4+x5+x6+x7, data = bigdf, hidden = 2, err.fct = "ce",
               linear.output = FALSE)

nn
plot(nn)
nn$net.result # overall result i.e. output for each repclication
nn$weights
nn$result.matrix
nn$covariate
bigdf$x001
nn$net.result[[1]]
nn1 = ifelse(nn$net.result[[1]]>0.5,1,0)
nn1
misClasificationError = mean(bigdf$x001 ! =nn1)
misClasificationError
OutPutVsPred = cbind(bigdf$x001,nn1)
OutPutVsPred

nn.bp = neuralnet(
  formul = y~x2+x3+x4+x5+x6+x7, data = bigdf, hidden = 2,
           learningrate = 0.01,
           algorithm = "backprop",
           err.fct = "ce",
           linear.output = FALSE)

nn.bp
nn

new.output = compute(nn,covariate=matrix(c(22,1,0,0,
                                           22,1,1,0,
                                           22,1,0,1,
                                           22,1,1,1),
                                         byrow = TRUE, ncol = 4))

new.output$net.result


#visualise results
par(mfrow=c(2,2))
gwplot(nn,selected.covariate = "x2",
       min=-2.5, max=5)
gwplot(nn,selected.covariate = "x3",
       min=-2.5, max=5)
gwplot(nn,selected.covariate = "x4",
       min=-2.5, max=5)
gwplot(nn,selected.covariate = "x5",
       min=-2.5, max=5)
gwplot(nn,selected.covariate = "x6",
       min=-2.5, max=5)
gwplot(nn,selected.covariate = "x7",
       min=-2.5, max=5)



setwd("~/R Working Directory")
rm(list = ls())#clear memory
.rs.restartR()#clear memory


library(readxl)


na.omit(bigdf)
bigdf <- bigdf[1:10,]
install.packages("neuralnet")
library(neuralnet)
proportion <- 0.8 # set to split
index  <- sample(1:nrow(bigdf), round(proportion*nrow(bigdf)))

maxs <- apply(bigdf, 2, max)
mins <- apply(bigdf, 2, min)
scaled <- as.data.frame(scale(bigdf, center = mins, scale = maxs-mins))

train_ <- scaled[index,]
test_ <- scaled[-index,]

library(neuralnet)
n <- names(train_)
f <- as.formula(paste("medv ~", paste(n[!n %in% "medv"], collapse = " + ")))
nn <- neuralnet(f,data=train_,hidden=c(5,3),linear.output=T)











train_bigdf <- scaled[index, ]
na.omit(train_bigdf)
test_bigdf <- scaled[-index, ]
na.omit(test_bigdf)
head(train_bigdf)

head(test_bigdf)

bigdf_n <- neuralnet(x001 ~ x002+x003+x004+x005+x006+x007+x008+x009+x010+x011+
                       x012+x013+x014+x015+x016+x017+x018+x019+x020+x021+
                       x022+x023+x024+x025+x026+x027+x028+x029+x030+x031+
                       x032+x033+x034+x035+x036+x037+x038+x039+x040+x041+
                       x042+x043+x044+x045+x046+x047+x048+x049+x050+x051+
                       x052+x053+x054+x055+x056+x057
                     , train_bigdf , hidden = c(1))

plot(bigdf_n)

pred_test <- compute(bigdf,test_bigdf[,1:57])
predtestResult <- pred_test$net.result
predtestResult <- as.data.frame((predtestResult))

colnames(predtestResult) <- c("x001p")
bigdf_testdataset <- colnames(predtestResult)[apply(predtestResult,1,which.max)]
bigdf_testdataset <- as.data.frame(bigdf_testdataset)
table(re)


# installing/loading the package:
if(!require(installr)) {
  install.packages("installr"); require(installr)} #load / install+load installr

# using the package:
updateR() # this will start the updating process of your R installation.  It will check for newer versions, and if one is available, will guide you through the decisions you'd need to make.

install.packages("neuralnet")
library(neuralnet)

#buradan itibaren kullanacagiz

library(readxl)
bigdf <- read_excel("C:/Users/arif.tanis/Desktop/bigdataA.xlsx")

#eksik verileri satırlardan çıkarma
bigdf<-na.omit(bigdf)

#histograma bakıyoruz
hist(bigdf$return)

bigdf$x001e <- cut(bigdf$return, breaks=c(-0.225785401, -0.02, 0, 0.02, 0.06, 0.127589637), labels=paste("", 1:5, sep=""))  ##burada dilimlere ayırıyoruz
View(bigdf)

as.numeric(bigdf$x001e)

iris <- bigdf2 #dfi olusturduk
View(iris) #dfi goruntuledik
set.seed(2) #random generator
proportion <- 0.8 # set to split
index <- sample(1:nrow(iris), round(proportion*nrow(iris))) #datayi %80 %20 bolen bir index olusturduk



m <- as.matrix(iris[index, ]) 
na.omit(m)#missing data ayıklama
train_iris <- m
train_iris <- as.data.frame(train_iris)
na.omit(train_iris)
train_iris <- iris[index, ]
View(train_iris) #training df parçasını olusturduk


summary(train_iris)
View(train_iris)


test_iris <- iris[index, ] #testing df parçasını oluşturduk
train_iris <- iris[-index,] #train df parçasını oluşturduk

NROW(train_iris)
NROW(test_iris)

as.numeric(train_iris$x001e)

iris_n <- neuralnet(x001e ~ sharpe + treynor + jense + beta + stdev, train_iris, hidden = 3,
                    stepmax=1e7, threshold = 0.01, algorithm = "rprop+", err.fct = "sse")
plot(iris_n) #neural network fitting code

my_list <- iris_n$weights  #listeyi içerden çekiyoruz
View(my_list[[1]][[1]]) # weightlerin listesi
weight_listesi <- my_list[[1]][[1]] # 1 in 1 i 1 in ikisi 2 nin 1 i şeklinde açılıyor liste içeriğini data frame e çevireceğiz
weight_listesi <- as.data.frame(weight_listesi) 




pred_test <- compute(iris_n,bigdf[,6:10]) # predictionlarımızı test ediyoruz
predtestResult <- pred_test$net.result # predictionlarımızı kaydediyoruz
predtestResult <- as.data.frame(predtestResult) # predictionlarımızı kaydediyoruz sonra df yapıyoruz

colnames(predtestResult)<-("x001p") # tahmin df'in kolon ismini değiştirdik
View(predtestResult)
bigdf3 <- bigdf
bigdf3$x001p <- predtestResult

write.csv(predtestResult, file = "predtestResult.csv") #predtestresult datasını yazdırıyoruz.
write.csv(test_iris, file = "test_iris.csv") #predtestresult datasını yazdırıyoruz.
write.csv(bigdf, file = "bigdf.csv") #predtestresult datasını yazdırıyoruz.



predtestResult <- ceiling(predtestResult)

predtestResultC <- cut(predtestResult$x001e, breaks=c(-0.1130992, -0.0065608, 0.0897254, 0.1244106, 0.2211354, 0.6510209), labels=paste("Star", 1:5, sep=""))  ##burada dilimlere ayırıyoruz
View(predtestResultC)


gwplot(iris_n, selected.covariate="x005")

plot(iris_n, rep="best")


library(dplyr)
library(tidyr)

est_new2 <- ceiling(est_new[,2])## 2. sütunun virgülden sonra rakamları kaldırıyoruz
View(est_new)


est_new2 <- spread(est_new, ass_n, x001e)  ##datayı tabloya dönüstürme

write.csv(est_new2, file = "est_new2.csv")  ## save data

w_result<-result.matrix(iris_n)






=IF(E3>0,08481;5;(IF(E3>0,03761;4;(IF(E3>-0,00958;3;(IF(E3>-0,05678;2;1)))))))
