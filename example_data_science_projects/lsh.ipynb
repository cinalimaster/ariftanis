{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locality Sensitive Hashing\n",
    "(by Tevfik Aytekin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximate Nearest Neighbor\n",
    "\n",
    "Finding nearest neighbors in a set of objects is a very general problem which has applications in many areas. If the size of the set of objects is very large then an exhaustive pairwise comparision of all ojects can be very costly.\n",
    "\n",
    "**Randomized near-neighbor reporting:** Given a set $P$ of points in a $d$-dimensional space $\\mathbb{R}^d$, and parameters $R > 0, > δ > 0$, construct a data structure which, given any query point $q$, reports each $R$-near neighbor of $q$ in $P$ with probability $1 − δ$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The main idea of LSH\n",
    "\n",
    "The main idea of LSH is to design hash functions such that the probability of a collision is much higher for closer points compared to points which are far apart. Given such hash functions one can hash a query point and retrive the elements in the buckets that contain the query point.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formal Definition of LSH \n",
    "(following definition and figure is taken from [mmds book](http://www.mmds.org/) where you can read more about LSH)\n",
    "\n",
    "Let $d_1 < d_2$ be two distances according to some distance measure $d$. A family $F$ of functions is said to be $(d_1, d_2, p_1, p_2)-sensitive$ if for every $f$ in $F$:\n",
    "1. If $d(x,y) ≤ d_1$, then the probability that $f(x) = f(y)$ is at least $p_1$. \n",
    "2. If $d(x,y) ≥ d_2$, then the probability that $f(x) = f(y)$ is at most $p_2$.\n",
    "\n",
    "In order for a LSH family to be useful: $p_1 > p_2$.\n",
    "\n",
    "<img src=\"images/lsh.png\" width = \"400\">\n",
    "\n",
    "Once you have a family $F$ of functions we can amplify the gap between the $p_1$ and $p_2$ by AND and OR constructions. \n",
    "\n",
    "Suppose we are given a $(d_1, d_2, p_1, p_2)-sensitive$ family $F$. We can make an AND construction by building $g=(f_1,f_2,...,f_k)$ by choosing $k$ functions at random from $F$. We say that $g(x) = g(y)$ iff $g_i(x) = g_i(y)$ for all $i = 1, 2, . . . , k$.\n",
    "\n",
    "We can make OR constructions by building $h=(g_1,f_2,...,g_l)$ by choosing $l$ functions from the set of $g$ functions as defined above. at random from $F$. Note that all the $f_i$'s in each $g_j$ are choosen at random from $F$. We define $h(x) = h(y)$ iff $g_i(x) = g_i(y)$ for one or more values of $i$. \n",
    "\n",
    "We assume a seperate hash table for each $g_i$. We will insert every point $p$ by the key $q_i(p)$ into each bucket of $g_i$'s during the build phase of LSH. When a query point $q$ comes we will return the elemements in the buckets at each $g_i(q)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An LSH Function for Cosine Similarity\n",
    "\n",
    "For every distance metric (such as cosine, Jaccard, hamming, etc.) you should define a LSH family of hash functions. For cosine distance sign of the dot product of the data point with a random unit vector is used for construction the LSH. Each such random unit vector constitutes a different function in the LSH family F. The following figure illustrates why dot product with a random unit vector can be used to build an LSH family of function for cosine distance. \n",
    "\n",
    "<img src=\"images/lsh_cosine.jpg\" width = \"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "import time\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import itertools\n",
    "import pandas as pd\n",
    "#from tabulate import tabulate\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance measurement\n",
    "\n",
    "Nearest neighbor search: Suppose that we have a large dataset of vectors X and given a target vector we want to find the most similar k vectors to the target vector in the dataset X. Note that we can do this type of search more than once. \n",
    "\n",
    "First let us generate the dataset X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vectors = 100000\n",
    "dim = 10\n",
    "n_neighbors = 100\n",
    "n_queries = 2000\n",
    "\n",
    "target_vectors = np.random.randn(n_queries, dim)\n",
    "dataset = np.random.randn(n_vectors, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:20566.476106643677ms\n"
     ]
    }
   ],
   "source": [
    "ns = NaiveSearch(dataset)\n",
    "ns.build()\n",
    "tic = time.time()\n",
    "ns_nn = []\n",
    "for i in range(n_queries):\n",
    "    target_vector = target_vectors[i,:].reshape(1,dim)\n",
    "    neighbors = ns.find_nn(target_vector, n_neighbors)\n",
    "    ns_nn.append(neighbors)\n",
    "toc = time.time()\n",
    "print(\"Time:\"+str(1000*(toc-tic))+\"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "10\n",
      "0 1\n",
      "11\n",
      "0 2\n",
      "12\n",
      "0 3\n",
      "13\n",
      "0 4\n",
      "14\n",
      "0 5\n",
      "15\n",
      "1 0\n",
      "10\n",
      "1 1\n",
      "11\n",
      "1 2\n",
      "12\n",
      "1 3\n",
      "13\n",
      "1 4\n",
      "14\n",
      "1 5\n",
      "15\n",
      "2 0\n",
      "10\n",
      "2 1\n",
      "11\n",
      "2 2\n",
      "12\n",
      "2 3\n",
      "13\n",
      "2 4\n",
      "14\n",
      "2 5\n",
      "15\n",
      "3 0\n",
      "10\n",
      "3 1\n",
      "11\n",
      "3 2\n",
      "12\n",
      "3 3\n",
      "13\n",
      "3 4\n",
      "14\n",
      "3 5\n",
      "15\n",
      "4 0\n",
      "10\n",
      "4 1\n",
      "11\n",
      "4 2\n",
      "12\n",
      "4 3\n",
      "13\n",
      "4 4\n",
      "14\n",
      "4 5\n",
      "15\n",
      "Elapsed Time\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2251.501</td>\n",
       "      <td>2281.903</td>\n",
       "      <td>1881.211</td>\n",
       "      <td>716.468</td>\n",
       "      <td>715.501</td>\n",
       "      <td>640.685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4246.054</td>\n",
       "      <td>3099.028</td>\n",
       "      <td>2631.128</td>\n",
       "      <td>1587.320</td>\n",
       "      <td>1901.274</td>\n",
       "      <td>722.371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4561.662</td>\n",
       "      <td>3361.857</td>\n",
       "      <td>2754.723</td>\n",
       "      <td>2298.846</td>\n",
       "      <td>1595.129</td>\n",
       "      <td>1142.491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5469.603</td>\n",
       "      <td>3684.521</td>\n",
       "      <td>2880.174</td>\n",
       "      <td>2581.373</td>\n",
       "      <td>2066.969</td>\n",
       "      <td>1722.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5863.859</td>\n",
       "      <td>4703.014</td>\n",
       "      <td>3436.484</td>\n",
       "      <td>3047.911</td>\n",
       "      <td>2486.806</td>\n",
       "      <td>2136.813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         10        11        12        13        14        15\n",
       "1  2251.501  2281.903  1881.211   716.468   715.501   640.685\n",
       "2  4246.054  3099.028  2631.128  1587.320  1901.274   722.371\n",
       "3  4561.662  3361.857  2754.723  2298.846  1595.129  1142.491\n",
       "4  5469.603  3684.521  2880.174  2581.373  2066.969  1722.599\n",
       "5  5863.859  4703.014  3436.484  3047.911  2486.806  2136.813"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.149735</td>\n",
       "      <td>0.137700</td>\n",
       "      <td>0.109220</td>\n",
       "      <td>0.084290</td>\n",
       "      <td>0.076830</td>\n",
       "      <td>0.060785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.297170</td>\n",
       "      <td>0.241765</td>\n",
       "      <td>0.203355</td>\n",
       "      <td>0.159500</td>\n",
       "      <td>0.149875</td>\n",
       "      <td>0.110730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.385170</td>\n",
       "      <td>0.329770</td>\n",
       "      <td>0.277095</td>\n",
       "      <td>0.245390</td>\n",
       "      <td>0.199555</td>\n",
       "      <td>0.169950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.472820</td>\n",
       "      <td>0.395250</td>\n",
       "      <td>0.341090</td>\n",
       "      <td>0.308390</td>\n",
       "      <td>0.256225</td>\n",
       "      <td>0.211770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.532090</td>\n",
       "      <td>0.476835</td>\n",
       "      <td>0.423845</td>\n",
       "      <td>0.361585</td>\n",
       "      <td>0.304265</td>\n",
       "      <td>0.272705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         10        11        12        13        14        15\n",
       "1  0.149735  0.137700  0.109220  0.084290  0.076830  0.060785\n",
       "2  0.297170  0.241765  0.203355  0.159500  0.149875  0.110730\n",
       "3  0.385170  0.329770  0.277095  0.245390  0.199555  0.169950\n",
       "4  0.472820  0.395250  0.341090  0.308390  0.256225  0.211770\n",
       "5  0.532090  0.476835  0.423845  0.361585  0.304265  0.272705"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Neighbor Size\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>376.1320</td>\n",
       "      <td>397.0000</td>\n",
       "      <td>232.8455</td>\n",
       "      <td>118.2515</td>\n",
       "      <td>107.4095</td>\n",
       "      <td>60.6275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1167.7910</td>\n",
       "      <td>663.4810</td>\n",
       "      <td>444.0195</td>\n",
       "      <td>207.8125</td>\n",
       "      <td>216.2850</td>\n",
       "      <td>97.4130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1351.5915</td>\n",
       "      <td>812.6195</td>\n",
       "      <td>546.9365</td>\n",
       "      <td>436.7610</td>\n",
       "      <td>245.7855</td>\n",
       "      <td>187.5365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1791.2980</td>\n",
       "      <td>955.5080</td>\n",
       "      <td>681.5155</td>\n",
       "      <td>566.5705</td>\n",
       "      <td>337.8880</td>\n",
       "      <td>222.3765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1912.0350</td>\n",
       "      <td>1361.0680</td>\n",
       "      <td>996.6785</td>\n",
       "      <td>660.3095</td>\n",
       "      <td>402.4205</td>\n",
       "      <td>367.8485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          10         11        12        13        14        15\n",
       "1   376.1320   397.0000  232.8455  118.2515  107.4095   60.6275\n",
       "2  1167.7910   663.4810  444.0195  207.8125  216.2850   97.4130\n",
       "3  1351.5915   812.6195  546.9365  436.7610  245.7855  187.5365\n",
       "4  1791.2980   955.5080  681.5155  566.5705  337.8880  222.3765\n",
       "5  1912.0350  1361.0680  996.6785  660.3095  402.4205  367.8485"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#target_vector_b = target_vector\n",
    "#print(neighbors)\n",
    "min_n_random_vectors = 10\n",
    "max_n_random_vectors = 15\n",
    "max_n_bands = 5\n",
    "\n",
    "elapsed_time = np.zeros((max_n_bands, (max_n_random_vectors-min_n_random_vectors)+1))\n",
    "recall = np.zeros((max_n_bands, (max_n_random_vectors-min_n_random_vectors)+1))\n",
    "avg_neigbor_size = np.zeros((max_n_bands, (max_n_random_vectors-min_n_random_vectors)+1))\n",
    "\n",
    "for b in range(1, max_n_bands+1):\n",
    "    for v in range(min_n_random_vectors,max_n_random_vectors+1):\n",
    "        lsh_nn = []\n",
    "        lsh = LSH(dataset)\n",
    "        lsh.build(v, n_bands = b)\n",
    "        tic = time.process_time()\n",
    "        for i in range(n_queries):\n",
    "            target_vector = target_vectors[i,:].reshape(1,dim)\n",
    "            neighbors = lsh.find_nn(target_vector, n_neighbors, n_bands = b)\n",
    "            lsh_nn.append(neighbors)\n",
    "        toc = time.process_time()\n",
    "        print(b-1,v-min_n_random_vectors)\n",
    "        print(v)\n",
    "        elapsed_time[b-1,v-min_n_random_vectors] = (toc-tic)*1000\n",
    "        true_positives = sum([len(np.intersect1d(ns_nn[i], lsh_nn[i][:n_neighbors])) for i in range(n_queries)])\n",
    "        recall[b-1,v-min_n_random_vectors] = true_positives / (n_queries*n_neighbors)\n",
    "        avg_neigbor_size[b-1,v-min_n_random_vectors] = len(list(itertools.chain(*lsh_nn)))/n_queries\n",
    "    \n",
    "\n",
    "\n",
    "#pd.DataFrame({\"Number of Random Vectors:\": range(min_n_random_vectors,max_n_random_vectors+1), \"Elapsed Time\":elapsed_time, \"Recall\": recall, \"Avg. Neighbor Size\": avg_neigbor_size}) \n",
    "elapsed_time_df = pd.DataFrame(elapsed_time)\n",
    "recall_df = pd.DataFrame(recall)\n",
    "avg_neigbor_size_df = pd.DataFrame(avg_neigbor_size)\n",
    "\n",
    "row_names = [str(i) for i in range(1, max_n_bands+1)]\n",
    "column_names = [str(i) for i in range(min_n_random_vectors, max_n_random_vectors+1)]\n",
    "elapsed_time_df.columns = recall_df.columns = avg_neigbor_size_df.columns = column_names\n",
    "elapsed_time_df.index = recall_df.index = avg_neigbor_size_df.index = row_names\n",
    "print(\"Elapsed Time\")\n",
    "display(elapsed_time_df)\n",
    "print(\"Recall\")\n",
    "display(recall_df)\n",
    "print(\"Avg. Neighbor Size\")\n",
    "display(avg_neigbor_size_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(elapsed_time_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[str(i) for i in range(1, max_n_bands+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveSearch:\n",
    "    def __init__(self, data):\n",
    "        # data is a n-by-d matrix where d is the length of the vectors\n",
    "        # and n is the number of vectors. \n",
    "        self.data = data\n",
    "        self.norms = None\n",
    "        self.data_normalized_T = None\n",
    "    \n",
    "        \n",
    "    def build(self):\n",
    "        self.norms = np.linalg.norm(self.data, axis=1)\n",
    "        self.norms.shape = (len(self.norms), 1)\n",
    "        \n",
    "        data_normalized = np.divide(self.data, self.norms)\n",
    "        self.data_normalized_T = data_normalized.T\n",
    "            \n",
    "            \n",
    "    def find_nn(self, target_vector, n_neighbors=10):\n",
    "\n",
    "        #target_vector_normalized = np.linalg.norm(target_vector)\n",
    "        \n",
    "        sims = np.dot(target_vector,self.data_normalized_T)[0]\n",
    "        return sims.argsort()[::-1][:n_neighbors]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSH:\n",
    "    def __init__(self, data):\n",
    "        # data is a n-by-d matrix where d is the length of the vectors\n",
    "        # and n is the number of vectors. \n",
    "        self.data = data\n",
    "        self.bands = []\n",
    "        self.random_vectors = []\n",
    "    \n",
    "    def build(self, n_random_vectors, n_bands = 1):\n",
    "        for b in range(n_bands):\n",
    "            # generate random vectors\n",
    "            self.bands.append({})\n",
    "            dim = self.data.shape[1]\n",
    "            self.random_vectors.append(np.random.randn(n_random_vectors, dim))\n",
    "            # generate dim-by-n index bits\n",
    "            sign_bits = np.dot(self.data, self.random_vectors[b].T) >= 0\n",
    "            n_data_vectors = self.data.shape[0]\n",
    "            for i in range(n_data_vectors):\n",
    "                key = tuple(sign_bits[i,:])\n",
    "                if key not in self.bands[b]:\n",
    "                    self.bands[b][key] = []\n",
    "                self.bands[b][key].append(i)\n",
    "            \n",
    "            \n",
    "    def find_nn(self, target_vector, n_neighbors=10, n_bands = 1):\n",
    "\n",
    "        candidate_ids = []\n",
    "        for b in range(n_bands):\n",
    "            sign_bits = (np.dot(target_vector, self.random_vectors[b].T) >= 0).flatten()\n",
    "            sign_bits_tuple = tuple(sign_bits)\n",
    "            ids = self.bands[b].get(sign_bits_tuple)\n",
    "            if ids is None: \n",
    "                ids = []\n",
    "            candidate_ids = candidate_ids + ids\n",
    "        if len(candidate_ids) > 0:\n",
    "                candidate_vectors = self.data[candidate_ids, :]\n",
    "                sims = 1 - pairwise_distances(target_vector, candidate_vectors, metric='cosine').flatten()\n",
    "                sorted_nn = sims.argsort()[::-1]\n",
    "                return np.array([candidate_ids[i] for i in sorted_nn])\n",
    "        else:\n",
    "            return []\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making sense of the cost of pairwise similarity computation\n",
    "\n",
    "Suppose that we have n objects represented as vectors of size d. The cost of computing all pairwise similarities is $O(n^2d)$. When $n$ is large the cost of this computation can be quite large. And in some applications like finding near duplicate web pages, in order to eliminate them from search results, $n$ (number of web pages) can be really large.\n",
    "\n",
    "To get a sense of this cost below is a simple code which measures the time two multiply two matrices of size $n$-by-$d$. (Note that some version of multiplication is needed in order to find similarities between the vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:4142.167ms\n"
     ]
    }
   ],
   "source": [
    "n = 10000\n",
    "d = 1000\n",
    "X = np.random.randn(n,d)\n",
    "tic = time.process_time()\n",
    "\n",
    "z = np.dot(X,X.T)\n",
    "\n",
    "toc = time.process_time()\n",
    "print(\"Time:\"+str(1000*(toc-tic))+\"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the time complexity is quadratic, we expect the figures in the following table if we increase $n$. You can try some larger $n$'s to test this.\n",
    "\n",
    "|  n | time  | \n",
    "|:---|:---|\n",
    "|  100k | 400 seconds  |\n",
    "|  1m | 11 hours  |\n",
    "|  10m | 46 days  |\n",
    "|  100m | 12 years  |\n",
    "|  1b | 12 centuries |\n",
    "\n",
    "The above results are taken on a 2,3 GHz Dual-Core Intel Core i5 laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
